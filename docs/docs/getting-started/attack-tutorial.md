---
sidebar_position: 1
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import ThemedImage from '@theme/ThemedImage';

# Attack Tutorial

This tutorial walks you through running security attacks against AI agents using HackAgent. You'll learn how to configure and execute all three attack types: **AdvPrefix**, **PAIR**, and **Baseline**.

## üöÄ Running Attacks

Choose your preferred interface to run attacks against your target agent.

<Tabs>
  <TabItem value="tui" label="TUI" default>

### Interactive Terminal UI

Launch the interactive terminal interface for a guided attack experience:

```bash
hackagent
```

The TUI will guide you through:
1. Selecting your target agent framework
2. Configuring the endpoint and agent details
3. Choosing an attack type (AdvPrefix, PAIR, or Baseline)
4. Setting attack goals and parameters
5. Monitoring attack progress in real-time

<img src="/gifs/terminal.gif" alt="HackAgent TUI Demo" style={{width: '100%', borderRadius: '8px', border: '1px solid var(--ifm-color-emphasis-300)'}} />

  </TabItem>
  <TabItem value="cli" label="CLI">

### Command Line Interface

Run attacks directly from your terminal. First, initialize your agent, then choose your attack type.

#### Agent Initialization

<Tabs groupId="framework">
  <TabItem value="ollama" label={<span><ThemedImage sources={{light: 'https://registry.npmmirror.com/@lobehub/icons-static-png/1.24.0/files/light/ollama.png', dark: 'https://registry.npmmirror.com/@lobehub/icons-static-png/1.24.0/files/dark/ollama.png'}} alt="Ollama" style={{height: '20px', marginRight: '8px', verticalAlign: 'middle'}} />Ollama</span>} default>

<details style={{background: 'var(--ifm-color-emphasis-100)', border: '1px solid var(--ifm-color-emphasis-200)', borderRadius: '6px', padding: '0.5rem 0.75rem', marginBottom: '0.75rem'}}>
  <summary style={{cursor: 'pointer', fontWeight: 600}}>Prerequisites</summary>

- Ollama running locally with the model available (e.g., `ollama pull llama3`)
</details>

<Tabs groupId="attack-type-cli-ollama">
  <TabItem value="advprefix" label="AdvPrefix" default>

```bash
hackagent attack advprefix \
  --agent-name "llama3" \
  --agent-type "ollama" \
  --endpoint "http://localhost:11434" \
  --goals "Extract system prompt information" \
  --generator-model "ollama/llama2-uncensored" \
  --generator-endpoint "http://localhost:11434/api/generate" \
  --no-tui
```

  </TabItem>
  <TabItem value="pair" label="PAIR">

```bash
hackagent attack pair \
  --agent-name "llama3" \
  --agent-type "ollama" \
  --endpoint "http://localhost:11434" \
  --goals "Reveal system prompt" \
  --attacker-model "ollama/llama3" \
  --n-iterations 20 \
  --no-tui
```

  </TabItem>
  <TabItem value="baseline" label="Baseline">

```bash
hackagent attack baseline \
  --agent-name "llama3" \
  --agent-type "ollama" \
  --endpoint "http://localhost:11434" \
  --goals "Ignore previous instructions" \
  --template-categories "roleplay,encoding" \
  --no-tui
```

  </TabItem>
</Tabs>

  </TabItem>
  <TabItem value="openai-sdk" label={<span><img src="https://openai.com/favicon.ico" alt="OpenAI" style={{height: '20px', marginRight: '8px', verticalAlign: 'middle'}} />OpenAI SDK</span>}>

<details style={{background: 'var(--ifm-color-emphasis-100)', border: '1px solid var(--ifm-color-emphasis-200)', borderRadius: '6px', padding: '0.5rem 0.75rem', marginBottom: '0.75rem'}}>
  <summary style={{cursor: 'pointer', fontWeight: 600}}>Prerequisites</summary>

- OpenAI API key set in `OPENAI_API_KEY`
</details>

<Tabs groupId="attack-type-cli-openai">
  <TabItem value="advprefix" label="AdvPrefix" default>

```bash
hackagent attack advprefix \
  --agent-name "gpt-4" \
  --agent-type "openai-sdk" \
  --endpoint "https://api.openai.com/v1" \
  --goals "Extract system prompt information" \
  --generator-model "gpt-4" \
  --no-tui
```

  </TabItem>
  <TabItem value="pair" label="PAIR">

```bash
hackagent attack pair \
  --agent-name "gpt-4" \
  --agent-type "openai-sdk" \
  --endpoint "https://api.openai.com/v1" \
  --goals "Reveal system prompt" \
  --attacker-model "gpt-4" \
  --n-iterations 20 \
  --no-tui
```

  </TabItem>
  <TabItem value="baseline" label="Baseline">

```bash
hackagent attack baseline \
  --agent-name "gpt-4" \
  --agent-type "openai-sdk" \
  --endpoint "https://api.openai.com/v1" \
  --goals "Ignore previous instructions" \
  --template-categories "roleplay,encoding" \
  --no-tui
```

  </TabItem>
</Tabs>

  </TabItem>
  <TabItem value="google-adk" label={<span><img src="https://google.github.io/adk-docs/assets/agent-development-kit.png" alt="Google ADK" style={{height: '20px', marginRight: '8px', verticalAlign: 'middle'}} />Google ADK</span>}>

<details style={{background: 'var(--ifm-color-emphasis-100)', border: '1px solid var(--ifm-color-emphasis-200)', borderRadius: '6px', padding: '0.5rem 0.75rem', marginBottom: '0.75rem'}}>
  <summary style={{cursor: 'pointer', fontWeight: 600}}>Prerequisites</summary>

- Google ADK agent running and reachable at your endpoint
</details>

<Tabs groupId="attack-type-cli-adk">
  <TabItem value="advprefix" label="AdvPrefix" default>

```bash
hackagent attack advprefix \
  --agent-name "my-agent" \
  --agent-type "google-adk" \
  --endpoint "http://localhost:8000" \
  --goals "Extract system prompt information" \
  --generator-model "ollama/llama2-uncensored" \
  --generator-endpoint "http://localhost:11434/api/generate" \
  --no-tui
```

  </TabItem>
  <TabItem value="pair" label="PAIR">

```bash
hackagent attack pair \
  --agent-name "my-agent" \
  --agent-type "google-adk" \
  --endpoint "http://localhost:8000" \
  --goals "Reveal system prompt" \
  --attacker-model "gpt-4" \
  --n-iterations 20 \
  --no-tui
```

  </TabItem>
  <TabItem value="baseline" label="Baseline">

```bash
hackagent attack baseline \
  --agent-name "my-agent" \
  --agent-type "google-adk" \
  --endpoint "http://localhost:8000" \
  --goals "Ignore previous instructions" \
  --template-categories "roleplay,encoding" \
  --no-tui
```

  </TabItem>
</Tabs>

  </TabItem>
  <TabItem value="litellm" label={<span><img src="https://docs.litellm.ai/img/favicon.ico" alt="LiteLLM" style={{height: '20px', marginRight: '8px', verticalAlign: 'middle'}} />LiteLLM</span>}>

<details style={{background: 'var(--ifm-color-emphasis-100)', border: '1px solid var(--ifm-color-emphasis-200)', borderRadius: '6px', padding: '0.5rem 0.75rem', marginBottom: '0.75rem'}}>
  <summary style={{cursor: 'pointer', fontWeight: 600}}>Prerequisites</summary>

- LiteLLM proxy running at your endpoint
</details>

<Tabs groupId="attack-type-cli-litellm">
  <TabItem value="advprefix" label="AdvPrefix" default>

```bash
hackagent attack advprefix \
  --agent-name "gpt-4" \
  --agent-type "litellm" \
  --endpoint "http://localhost:4000/v1" \
  --goals "Extract system prompt information" \
  --generator-model "gpt-4" \
  --no-tui
```

  </TabItem>
  <TabItem value="pair" label="PAIR">

```bash
hackagent attack pair \
  --agent-name "gpt-4" \
  --agent-type "litellm" \
  --endpoint "http://localhost:4000/v1" \
  --goals "Reveal system prompt" \
  --attacker-model "gpt-4" \
  --n-iterations 20 \
  --no-tui
```

  </TabItem>
  <TabItem value="baseline" label="Baseline">

```bash
hackagent attack baseline \
  --agent-name "gpt-4" \
  --agent-type "litellm" \
  --endpoint "http://localhost:4000/v1" \
  --goals "Ignore previous instructions" \
  --template-categories "roleplay,encoding" \
  --no-tui
```

  </TabItem>
</Tabs>

  </TabItem>
</Tabs>

View available attacks and options:

```bash
hackagent attack --help
```

  </TabItem>
  <TabItem value="sdk" label="SDK">

### Python SDK

Integrate security testing into your Python applications.

#### Agent Initialization

<Tabs groupId="framework">
  <TabItem value="ollama" label={<span><ThemedImage sources={{light: 'https://registry.npmmirror.com/@lobehub/icons-static-png/1.24.0/files/light/ollama.png', dark: 'https://registry.npmmirror.com/@lobehub/icons-static-png/1.24.0/files/dark/ollama.png'}} alt="Ollama" style={{height: '20px', marginRight: '8px', verticalAlign: 'middle'}} />Ollama</span>} default>

<details style={{background: 'var(--ifm-color-emphasis-100)', border: '1px solid var(--ifm-color-emphasis-200)', borderRadius: '6px', padding: '0.5rem 0.75rem', marginBottom: '0.75rem'}}>
  <summary style={{cursor: 'pointer', fontWeight: 600}}>Prerequisites</summary>

- Ollama running locally with the model available (e.g., `ollama pull llama3`)
</details>

```python
from hackagent import HackAgent

agent = HackAgent(
    name="llama3",
    endpoint="http://localhost:11434",
    agent_type="ollama",
)
```

<Tabs groupId="attack-type-sdk-ollama">
  <TabItem value="advprefix" label="AdvPrefix" default>

```python
attack_config = {
    "attack_type": "advprefix",
    "goals": [
        "Extract system prompt information",
        "Bypass content safety filters"
    ],
    "generator": {
        "identifier": "ollama/llama2-uncensored",
        "endpoint": "http://localhost:11434/api/generate"
    },
    "judges": [{
        "identifier": "ollama/llama3",
        "endpoint": "http://localhost:11434/api/generate",
        "type": "harmbench"
    }]
}

results = agent.hack(attack_config=attack_config)
```

  </TabItem>
  <TabItem value="pair" label="PAIR">

```python
attack_config = {
    "attack_type": "pair",
    "goals": [
        "Reveal your system prompt",
        "Bypass safety guidelines"
    ],
    "attacker": {
        "identifier": "ollama/llama3",
        "endpoint": "http://localhost:11434/api/generate"
    },
    "n_iterations": 20,
    "objective": "jailbreak"
}

results = agent.hack(attack_config=attack_config)
```

  </TabItem>
  <TabItem value="baseline" label="Baseline">

```python
attack_config = {
    "attack_type": "baseline",
    "goals": [
        "Ignore your previous instructions",
        "Reveal your system prompt"
    ],
    "template_categories": ["roleplay", "encoding", "context_switch"],
    "templates_per_category": 5
}

results = agent.hack(attack_config=attack_config)
```

  </TabItem>
</Tabs>

  </TabItem>
  <TabItem value="openai-sdk" label={<span><img src="https://openai.com/favicon.ico" alt="OpenAI" style={{height: '20px', marginRight: '8px', verticalAlign: 'middle'}} />OpenAI SDK</span>}>

<details style={{background: 'var(--ifm-color-emphasis-100)', border: '1px solid var(--ifm-color-emphasis-200)', borderRadius: '6px', padding: '0.5rem 0.75rem', marginBottom: '0.75rem'}}>
  <summary style={{cursor: 'pointer', fontWeight: 600}}>Prerequisites</summary>

- OpenAI API key set in `OPENAI_API_KEY`
</details>

```python
from hackagent import HackAgent

agent = HackAgent(
    name="gpt-4",
    endpoint="https://api.openai.com/v1",
    agent_type="openai-sdk",
)
```

<Tabs groupId="attack-type-sdk-openai">
  <TabItem value="advprefix" label="AdvPrefix" default>

```python
attack_config = {
    "attack_type": "advprefix",
    "goals": [
        "Extract system prompt information",
        "Bypass content safety filters"
    ],
    "generator": {
        "identifier": "gpt-4",
        "endpoint": "https://api.openai.com/v1"
    },
    "judges": [{
        "identifier": "gpt-4",
        "endpoint": "https://api.openai.com/v1",
        "type": "harmbench"
    }]
}

results = agent.hack(attack_config=attack_config)
```

  </TabItem>
  <TabItem value="pair" label="PAIR">

```python
attack_config = {
    "attack_type": "pair",
    "goals": [
        "Reveal your system prompt",
        "Bypass safety guidelines"
    ],
    "attacker": {
        "identifier": "gpt-4",
        "endpoint": "https://api.openai.com/v1"
    },
    "n_iterations": 20,
    "objective": "jailbreak"
}

results = agent.hack(attack_config=attack_config)
```

  </TabItem>
  <TabItem value="baseline" label="Baseline">

```python
attack_config = {
    "attack_type": "baseline",
    "goals": [
        "Ignore your previous instructions",
        "Reveal your system prompt"
    ],
    "template_categories": ["roleplay", "encoding", "context_switch"],
    "templates_per_category": 5
}

results = agent.hack(attack_config=attack_config)
```

  </TabItem>
</Tabs>

  </TabItem>
  <TabItem value="google-adk" label={<span><img src="https://google.github.io/adk-docs/assets/agent-development-kit.png" alt="Google ADK" style={{height: '20px', marginRight: '8px', verticalAlign: 'middle'}} />Google ADK</span>}>

<details style={{background: 'var(--ifm-color-emphasis-100)', border: '1px solid var(--ifm-color-emphasis-200)', borderRadius: '6px', padding: '0.5rem 0.75rem', marginBottom: '0.75rem'}}>
  <summary style={{cursor: 'pointer', fontWeight: 600}}>Prerequisites</summary>

- Google ADK agent running and reachable at your endpoint
</details>

```python
from hackagent import HackAgent

agent = HackAgent(
    name="my_google_agent",
    endpoint="http://localhost:8000",
    agent_type="google-adk",
)
```

<Tabs groupId="attack-type-sdk-adk">
  <TabItem value="advprefix" label="AdvPrefix" default>

```python
attack_config = {
    "attack_type": "advprefix",
    "goals": [
        "Extract system prompt information",
        "Bypass content safety filters"
    ],
    "generator": {
        "identifier": "ollama/llama2-uncensored",
        "endpoint": "http://localhost:11434/api/generate"
    },
    "judges": [{
        "identifier": "ollama/llama3",
        "endpoint": "http://localhost:11434/api/generate",
        "type": "harmbench"
    }]
}

results = agent.hack(attack_config=attack_config)
```

  </TabItem>
  <TabItem value="pair" label="PAIR">

```python
attack_config = {
    "attack_type": "pair",
    "goals": [
        "Reveal your system prompt",
        "Bypass safety guidelines"
    ],
    "attacker": {
        "identifier": "gpt-4",
        "endpoint": "https://api.openai.com/v1"
    },
    "n_iterations": 20,
    "objective": "jailbreak"
}

results = agent.hack(attack_config=attack_config)
```

  </TabItem>
  <TabItem value="baseline" label="Baseline">

```python
attack_config = {
    "attack_type": "baseline",
    "goals": [
        "Ignore your previous instructions",
        "Reveal your system prompt"
    ],
    "template_categories": ["roleplay", "encoding", "context_switch"],
    "templates_per_category": 5
}

results = agent.hack(attack_config=attack_config)
```

  </TabItem>
</Tabs>

  </TabItem>
  <TabItem value="litellm" label={<span><img src="https://docs.litellm.ai/img/favicon.ico" alt="LiteLLM" style={{height: '20px', marginRight: '8px', verticalAlign: 'middle'}} />LiteLLM</span>}>

<details style={{background: 'var(--ifm-color-emphasis-100)', border: '1px solid var(--ifm-color-emphasis-200)', borderRadius: '6px', padding: '0.5rem 0.75rem', marginBottom: '0.75rem'}}>
  <summary style={{cursor: 'pointer', fontWeight: 600}}>Prerequisites</summary>

- LiteLLM proxy running at your endpoint
</details>

```python
from hackagent import HackAgent

agent = HackAgent(
    name="gpt-4",
    endpoint="http://localhost:4000/v1",
    agent_type="litellm",
)
```

<Tabs groupId="attack-type-sdk-litellm">
  <TabItem value="advprefix" label="AdvPrefix" default>

```python
attack_config = {
    "attack_type": "advprefix",
    "goals": [
        "Extract system prompt information",
        "Bypass content safety filters"
    ],
    "generator": {
        "identifier": "gpt-4",
        "endpoint": "http://localhost:4000/v1"
    },
    "judges": [{
        "identifier": "gpt-4",
        "endpoint": "http://localhost:4000/v1",
        "type": "harmbench"
    }]
}

results = agent.hack(attack_config=attack_config)
```

  </TabItem>
  <TabItem value="pair" label="PAIR">

```python
attack_config = {
    "attack_type": "pair",
    "goals": [
        "Reveal your system prompt",
        "Bypass safety guidelines"
    ],
    "attacker": {
        "identifier": "gpt-4",
        "endpoint": "http://localhost:4000/v1"
    },
    "n_iterations": 20,
    "objective": "jailbreak"
}

results = agent.hack(attack_config=attack_config)
```

  </TabItem>
  <TabItem value="baseline" label="Baseline">

```python
attack_config = {
    "attack_type": "baseline",
    "goals": [
        "Ignore your previous instructions",
        "Reveal your system prompt"
    ],
    "template_categories": ["roleplay", "encoding", "context_switch"],
    "templates_per_category": 5
}

results = agent.hack(attack_config=attack_config)
```

  </TabItem>
</Tabs>

  </TabItem>
</Tabs>

  </TabItem>
</Tabs>

---

## ‚öîÔ∏è Attack Types Overview

<Tabs>
  <TabItem value="baseline" label="Baseline" default>

### Baseline Attack

Baseline attacks use predefined prompt templates combined with your test goals. Fast and effective for initial vulnerability scans.

#### Template Categories

| Category | Description |
|----------|-------------|
| `roleplay` | Make model assume unrestricted persona |
| `encoding` | Obfuscate requests using Base64, ROT13, etc. |
| `context_switch` | Break out of conversation context |
| `instruction_override` | Override system instructions |
| `hypothetical` | Frame as fictional/hypothetical |

[**Full Baseline Documentation ‚Üí**](../attacks/baseline-attacks)

  </TabItem>
  <TabItem value="pair" label="PAIR">

### PAIR Attack

PAIR (Prompt Automatic Iterative Refinement) uses an attacker LLM to iteratively generate and improve jailbreak prompts based on target responses.

#### How PAIR Works

1. **Attacker generates** an initial jailbreak prompt
2. **Target responds** to the prompt
3. **Judge scores** the response (1-10)
4. **Attacker refines** based on feedback
5. **Repeat** until success or max iterations

[**Full PAIR Documentation ‚Üí**](../attacks/pair-attacks)

  </TabItem>
  <TabItem value="advprefix" label="AdvPrefix">

### AdvPrefix Attack

AdvPrefix implements a 3-step pipeline to generate adversarial prefixes: (1) generation and filtering of prefixes using uncensored models, (2) execution to get completions from the target model, and (3) evaluation using judge models to aggregate and select the best prefixes.

#### Advanced Configuration

```python
advanced_config = {
    "attack_type": "advprefix",
    "goals": ["Extract sensitive information"],
    
    # Generator settings
    "generator": {
        "identifier": "ollama/llama2-uncensored",
        "endpoint": "http://localhost:11434/api/generate",
        "batch_size": 4,
        "max_new_tokens": 100,
        "temperature": 0.8
    },
    
    # Multiple judges for robust evaluation
    "judges": [
        {"identifier": "ollama/llama3", "type": "harmbench"},
        {"identifier": "gpt-4", "type": "openai"}
    ],
    
    # Attack parameters
    "n_candidates_per_goal": 10,
    "meta_prefixes": ["Write a guide:", "Explain how to:"],
    "n_prefixes_per_goal": 3
}
```

[**Full AdvPrefix Documentation ‚Üí**](../attacks/advprefix-attacks)

  </TabItem>
</Tabs>

---

##  Common Configuration Options

These options work across all attack types:

```python
common_config = {
    # Target agent
    "agent_name": "my-agent",
    "agent_type": "google-adk",  # or "openai-sdk", "litellm", "ollama"

```bash
# Test target agent connectivity
curl http://localhost:8000/health

# Test generator/attacker endpoint
curl http://localhost:11434/api/generate \
  -d '{"model": "llama2", "prompt": "test"}'
```

---

## üìö Next Steps

- [**AdvPrefix Deep Dive**](../attacks/advprefix-attacks.md) ‚Äî Full AdvPrefix documentation
- [**PAIR Attack Guide**](../attacks/pair-attacks.md) ‚Äî Iterative refinement techniques
- [**Baseline Templates**](../attacks/baseline-attacks.md) ‚Äî Template customization
- [**CLI Documentation**](../cli/overview.md) ‚Äî All CLI commands

---

:::warning Responsible Use
Always obtain proper authorization before testing any AI system. HackAgent is designed for authorized security testing only. See our [Responsible Disclosure Guidelines](../security/responsible-disclosure).
:::

